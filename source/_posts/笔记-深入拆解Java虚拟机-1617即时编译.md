---
title: 笔记-深入拆解Java虚拟机-1617即时编译
date: 2018-11-06 10:03:09
tags: JVM
categories: Java虚拟机
---

# 分层编译模式

## HotSpot 包含的即时编译器：
1. C1
2. C2
3. Graal（**实验性质**的即时编译器）

## Java 7 以前需要根据程序特性选择对应的即使编译器

### C1

- **执行时间较短**的程序。
- 对**启动性能**有要求的程序。
- C1 **编译效率较快**。
- 对应参数 -client

### C2

- **执行时间较长**的程序。
- 对**峰值性能**有要求的程序。
- C2 生成**代码的执行效率较快**。
- 对应参数 -server

## Java 7 引入分层编译

- **综合** C1 的**启动性能**优势和 C2 的**峰值性能**优势。
- 分层编译将 Java 虚拟机的执行状态**分为 5 个层次**。
	
	0.解释执行
	
	1.执行不带 profiling 的 C1 代码
	
	2.执行仅带方法调用次数和循环回边执行次数 profiling 的C1 代码
	
	3.执行带所有 profiling 的 C1 代码
	
	4.执行 C2 代码

- C2 代码的执行效率比 C1 代码高 30% 以上。
- C1 执行效率 1 层 > 2 层 > 3 层。（1 层比 2 层稍高，2 层比 3 层高 30% 以上）。

## profile

- profiling：在程序执行过程中，收集能够**反映程序执行状态的数据**。
- 这里所收集的数据我们称之为程序的 profile。
- 例如 JDK 附带的 hprof。
- profiler 大多通过**注入**或 **JVMTI 事件**来实现。
- **第 0 层和第 3 层还会收集用于第 4 层 C2 编译的数据。**

如：分支跳转字节码的分支 profile（branch profile）（跳转次数和不跳转次数），非私有实例方法调用指令，强制类型转换 checkcast 指令，类型测试 instanceof 指令，引用类型的数组存储 aastore 指令的 profile（receiver type profile）。

- 分支 profile 和类型 profile 的收集会给应用程序**带来不少性能开销**。
- 通常情况，**不会在解释执行中收集**分支 profile 和类型 profile。
- **只有触发 C1 编译后**，JVM 认为可能被 C2 编译，才收集这些 profile。
- 比较**极端情况**下，JVM 才会在**解释执行时收集** profile（如等待 C1 编译的方法过多时）。
- C2 可以根据收集到的数据进行猜测，作出比较**激进的优化**。

### 基于分支 profile 的优化

- 根据条件跳转指令的分支 profile，即时编译器可以将**从未执行过的分支剪掉**。
	- **节省编译时间**和部署代码要消耗的**内存空间**。
	- 将**精简程序的数据流**，触发更多的优化。

- 根据分支 profile，计算每一条程序执行路径的概率，**优化优先处理概率较高的路径**。

### 基于类型 profile 的优化

#### instanceof 测试

- 目标类型是 final 类型，只比较测试对象的动态类型是否为该类型。
- 目标类型是非 final 类型，依次测试该类，该类的父类、祖先类，该类所直接或者间接实现的接口。

#### instanceof 以及方法调用的类型 profile

- **假设对象的动态类型仅为类型 profile 中的那几个。**
- **针对分支 profile 优化。**
- **对方法调用的条件去虚化内联。**

### 去优化
> 即从执行即时编译生成的机器码切换回解释执行。

- 当**假设失败**的情况下，JVM 将**去优化**。
- 生成的机器码中，即时编译器在**假设失败的位置上插入一个陷阱**（trap）。
- 陷阱实际上是一条 call 指令，调用至 Java 虚拟机专门负责去优化的方法。
- 与普通的 call 指令的区别：去优化方法会更改栈上的返回地址，并不再返回即时编译器生成的机器码中。
- **去优化过程非常复杂。**
- 生成的机器代码和原本的字节码差异非常大。
- 需要将当前机器码的执行状态转换至某一字节码之前的执行状态，并从该字节码开始执行。
- 这便要求即时编译器在编译过程中**记录好这两种执行状态的映射**。

#### 去优化的原因与优化无关
> 即使重新编译也不会改变生成的机器码。

- 生成的机器码可以在调用去优化方法时传入 Action_None。
- 表示**保留这一份机器码**。
- 在下一次调用该方法时重新进入这一份机器码。

#### 去优化的原因与静态分析的结果有关

- 生成的机器码可以在调用去优化方法时传入 Action_Recompile。
- 表示**不保留这一份机器码**。
- 但是可以**不经过重新 profile，直接重新编译**。

#### 去优化的原因与基于 profile 的激进优化有关

- 生成的机器码需要在调用去优化方法时传入 Action_Reinterpret。
- 表示**不保留这一份机器码**。
- 而且**需要重新收集程序的 profile**。

## 编译路径

- **1 层和 4 层为终止状态。**
- 一个方法被终止状态编译后，如果编译后的代码没有失效，JVM 不再发出该方法的编译请求。

![image](http://pcrioz2ch.bkt.clouddn.com/JVM/16/compile_path.png)

### 通常情况

- 热点方法会被第 3 层的 C1 编译，再被第 4 层的 C2 编译。

### 琐碎的方法

- **字节数少**，且第 3 层的 profiling **没有可收集的数据**的方法。
- JVM 断定该方法对于 **C1 代码和 C2 代码执行效率相同**。
- 在第 3 层编译后，直接用第 1 层的 C1 编译。

### C1 忙碌的情况

- 解释执行过程中进行 profiling。
- 然后直接由第 4 层的 C2 编译。

### C2 忙碌的情况

- 方法先被第 2 层的 C1 编译。
- 再被第 3 层的 C1 编译，减少在第 3 层的执行时间。

## Java 8

- 默认开启分层编译。
- 不管分层编译是否开启，原本的选择即时编译器的参数都无效（-client 和 -server）。
- 关闭分层编译情况下，JVM 采用 C2。
- 只使用 C1：使用参数 -XX:TieredStopAtLevel=1，解释执行后直接由 1 层的 C1 编译。

# 即时编译的触发

- 根据方法的**调用次数**和**循环回边的执行次数**来触发。
- profiling 中包含上述次数。
- **解释执行和 C1 代码中增加循环回边计数器的位置不同**，但不会对程序照成影响。
- JVM **不对计数器进行同步**，收集的几次为非精确值。
- 即时编译的**触发不需要非常精确的值**。
- 不启用分层编译，超过由参数 -XX:CompileThreshold 指定的阈值时（使用 C1 时，该值为 1500；使用 C2 时，该值为 10000），会触发即时编译。
- 启用分层编译，JVM 不采用由参数 -XX:CompileThreshold 指定的阈值，使用另一套阈值系统。阈值大小**动态调整**。
- 动态调整：比较阈值时，将阈值与某个**系数 s** 相乘。
- 该系数与**当前待编译的方法数目**成**正相关**，与**编译线程的数目**成**负相关**。
- 64 位 JVM中，默认情况下**编译线程的总数目**根据**处理器数量来调整**，（对应参数 -XX:+CICompilerCountPerCPU，默认为 true；当通过参数 -XX:+CICompilerCount=N 强制设定总编译线程数目时，CICompilerCountPerCPU 将被设置为 false）。
- JVM 将编译线程按照 1:2 的比例分配给 C1 和 C2（至少各为 1 个）。

```
对于核及以上的机器，总的编译线程的数目为：
n = log2(N) * log2(log2(N)) * 3 / 2
其中 N 为 CPU 核心数目。
```

启用分层编译时的具体触发条件：

```
当方法调用次数大于由参数 -XX:TierXInvocationThreshold 指定的阈值乘以系数，或者当方法调用次数大于由参数 -XX:TierXMINInvocationThreshold 指定的阈值乘以系数，并且方法调用次数和循环回边次数之和大于由参数 -XX:TierXCompileThreshold 指定的阈值乘以系数时，便会触发 X 层即时编译。

触发条件为：
i > TierXInvocationThreshold * s || (i > TierXMinInvocationThreshold * s  && i + b > TierXCompileThreshold * s)
```

# OSR 编译

- JVM 还存在另一种以**循环为单位**的即时编译（On-Stack-Replacement（OSR）编译）。
- **循环回边计数器用来触发**这种类型的编译的。
- 不启用分层编译情况，触发 OSR 编译的阈值是由参数 -XX:CompileThreshold 指定的阈值的倍数。

计算方法：

```
(OnStackReplacePercentage - InterpreterProfilePercentage)/100

其中 -XX:InterpreterProfilePercentage 的默认值为 33，当使用 C1 时 -XX:OnStackReplacePercentage 为 933，当使用 C2 时为 140。
也就是说，默认情况下，C1 的 OSR 编译的阈值为 13500，而 C2 的为 10700。
```

- 启用分层编译的情况下，触发 OSR 编译的阈值则由参数 -XX:TierXBackEdgeThreshold 指定的阈值乘以系数。
- OSR 编译在**正常的应用程序**中**不多见**。它只在**基准测试**时比较**常见**。

# 问题

Q：**为什么不把所有代码都即时编译一下呢？这样程序的执行效率不是更快吗？**

A：即时编译是以方法为单位的。**动态编译比较耗时**，如果花了大量CPU资源编译出来的机器码运行不了几次，就很浪费了。

***

Q：为什么要用分层编译呢？**使用最快的编译代码编译器编译的代码不是更好吗？**

A：**机器码越快，需要的编译时间就越长。分层编译是一种折衷的方式**，既能够满足部分不那么热的代码能够在短时间内编译完成，也能满足很热的代码能够拥有最好的优化。

# 参考

> https://time.geekbang.org/column/article/14061
> https://time.geekbang.org/column/article/14070